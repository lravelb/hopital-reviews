# ğŸ§  Patient Sentiment Analysis Using NLP & LLMs

This project analyzes open-ended patient reviews to predict sentiment (positive or negative) using Natural Language Processing (NLP) techniques and Large Language Models (LLMs).

## ğŸš€ Project Overview

- **Goal**: Classify patient feedback based on sentiment
- **Dataset**: 996 hospital reviews with labeled sentiment
- **Techniques used**:
  - Text cleaning and preprocessing (NLTK, regex)
  - Exploratory Data Analysis (word clouds, word frequencies, review length)
  - Feature extraction with TF-IDF
  - Sentiment classification using:
    - Logistic Regression (baseline)
    - distilBERT LLM from Hugging Face (zero-shot)

## ğŸ—‚ï¸ Project Structure

<pre><code>
patient-sentiment-healthcare/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original dataset
â”‚ â””â”€â”€ processed/ # Cleaned dataset
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_data_cleaning_and_eda.ipynb # Data cleaning + EDA
â”‚ â””â”€â”€ 02_modeling_and_llm_comparison.ipynb # Model training + LLM comparison
â”œâ”€â”€ README.md
</code></pre>

## ğŸ“Š Results Summary

### Logistic Regression (TF-IDF)

- Accuracy: 0.86
- High precision on positive class
- Poor recall on negative class

### distilBERT (LLM)

- Accuracy: 0.78
- Much better at identifying negative reviews
- Balanced recall across classes

## ğŸ§ª Example Review

> "Wait hour despite appointment isnâ€™t first time happened understanding manage appointment queue itâ€™s random unorganised lot scope improve"

--> Detected as **NEGATIVE** by distilBERT

## ğŸ› ï¸ Tech Stack

- Python, Pandas, Scikit-learn, NLTK, Matplotlib, Seaborn
- Hugging Face Transformers (distilBERT)
- Google Colab (for LLM execution)

## ğŸ“ How to Run

1. Open `02_modeling_and_llm_comparison.ipynb` in [Google Colab](https://colab.research.google.com/)
2. Mount your Google Drive and upload the cleaned dataset (or use the one provided)
3. Run the cells to explore, train, and evaluate both models

